{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Zlt36SevIt4B"
      ],
      "authorship_tag": "ABX9TyOvcHY4oO9RBhS3w0Padmg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maximilianwte/ChatGPT-for-Literature-Analysis/blob/main/ChatGPT_for_Literature_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import all necessary libraries"
      ],
      "metadata": {
        "id": "6QLZ5kgNI-1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain openai PyPDF2 faiss-cpu tiktoken\n",
        "\n",
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI\n",
        "import re\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "hABgdofBIGtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETTINGS (changing these parameters changes cost)\n",
        "\n",
        "TEXT_PIECE_LENGTH = 1500   # other examples: 500, 1000, 2500; maximum: 3000\n",
        "NUM_PIECES_CONTEXT = 3   # other examples: 1-10"
      ],
      "metadata": {
        "id": "TogeBc5jSmvz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(reader):\n",
        "  raw_text = ''\n",
        "  for i, page in enumerate(reader.pages):\n",
        "      text = page.extract_text()\n",
        "      if text:\n",
        "          raw_text += text\n",
        "\n",
        "  text_splitter = CharacterTextSplitter(        \n",
        "      separator = \"\\n\",\n",
        "      chunk_size = TEXT_PIECE_LENGTH,\n",
        "      chunk_overlap  = 100,\n",
        "      length_function = len,\n",
        "  )\n",
        "  return text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "0dxfD4hXJlG5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Connect the Notebook to OpenAI to use ChatGPT\n",
        "\n",
        "- Click on this link to open the OpenAI platform: https://platform.openai.com/account/api-keys (If you don't have an account at openai yet, you can create one for free there)\n",
        "- Create a new secret key and copy it below at the variable \"OPEN_AI_KEY\"\n",
        "- Run the cell to activate the connection to OpenAI. Then you can use ChatGPT from this notebook"
      ],
      "metadata": {
        "id": "0kLr84muIPv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPEN_AI_KEY = \"\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPEN_AI_KEY\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "HlpVVIgeItZ3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Download Example PDF to test"
      ],
      "metadata": {
        "id": "Zlt36SevIt4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "M5FSrEXdHwxR"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def download_pdf(url, save_path):\n",
        "    response = requests.get(url)\n",
        "    with open(save_path, 'wb') as file:\n",
        "        file.write(response.content)\n",
        "\n",
        "example_download_url = 'https://github.com/Maximilianwte/ChatGPT-for-Literature-Analysis/raw/main/brandselfie.pdf'\n",
        "download_pdf(example_download_url, '/content/BrandSelfie.pdf')\n",
        "\n",
        "example_download_url = 'https://github.com/Maximilianwte/ChatGPT-for-Literature-Analysis/raw/main/CauseRelatedMarketing.pdf'\n",
        "download_pdf(example_download_url, '/content/CauseRelatedMarketing.pdf')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask questions to a single document"
      ],
      "metadata": {
        "id": "299f5frwJJ13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DOCUMENT_PATH = '/content/BrandSelfie.pdf' # here put in the path to the pdf you want to load\n",
        "\n",
        "reader = PdfReader(DOCUMENT_PATH)\n",
        "texts = process_text(reader)\n",
        "docsearch = FAISS.from_texts(texts, embeddings)\n",
        "chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "GmiAaRH3H5t4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a better understanding of how to ask good questions to ChatGPT see the documentation of OpenAI: https://platform.openai.com/docs/guides/gpt-best-practices/six-strategies-for-getting-better-results"
      ],
      "metadata": {
        "id": "6ric4VknJhN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"What type of data is used in the paper? Image data, audio data?\"\n",
        "\n",
        "docs = docsearch.similarity_search(QUESTION, k=NUM_PIECES_CONTEXT)\n",
        "chain.run(input_documents=docs, question=QUESTION)"
      ],
      "metadata": {
        "id": "087nu3uG8cQ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b03d6a6-1f5b-4ee9-8b6d-19077e93513c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The paper uses image data.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "QUESTION = \"What model is used for image data?\"\n",
        "\n",
        "docs = docsearch.similarity_search(QUESTION, k=NUM_PIECES_CONTEXT)\n",
        "chain.run(input_documents=docs, question=QUESTION)"
      ],
      "metadata": {
        "id": "fMtsD2mxyQ2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cf5b14f0-7177-40e0-a14e-7a1709688361"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Transfer learning is used to fine-tune an existing deep neural network pretrained on 1.2 million images on ImageNet (Deng et al. 2009).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See how much your questions cost you on the OpenAI platform: https://platform.openai.com/account/usage \n",
        "\n",
        "(it takes ca. 5 minutes to refresh your costs after you asked new questions)"
      ],
      "metadata": {
        "id": "MqHSPo2PLJXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask the same questions to multiple PDF's"
      ],
      "metadata": {
        "id": "--w3VOGILhDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDER_PATH = \"/content\" # Change this path to the folder you want to analyze\n",
        "\n",
        "PDF_PATHS = glob.glob(f'{FOLDER_PATH}/*.pdf')\n",
        "print(f'You have {len(PDF_PATHS)} PDF in your folder.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-Ae3qj9K_M3",
        "outputId": "62cb5fe7-8320-4665-ca59-3ca333b3eabf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 2 PDF in your folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For your literature analysis it makes sense to ask QUESTIONS about the research questions, data used, methods, results etc. of the paper. Still, due to ChatGPT being able to hallucinate, please make sure to check the results afterwards."
      ],
      "metadata": {
        "id": "s66_3-eCPVZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter the 1. title of the question for your table and the 2. question in words to ask ChatGPT\n",
        "QUESTIONS = [\n",
        "    ('Topic', 'What is the topic of the article?'),\n",
        "    ('Data', 'What data was used for the analysis?')\n",
        "]"
      ],
      "metadata": {
        "id": "E9LDMwzHMcow"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "for i, PDF in tqdm.tqdm(enumerate(PDF_PATHS), desc='PDF number:'):\n",
        "  df.at[i, 'filename'] = PDF\n",
        "  for q_index in tqdm.tqdm(range(len(QUESTIONS)), desc='Question number: '):\n",
        "    reader = PdfReader(PDF)\n",
        "    texts = process_text(reader)\n",
        "    docsearch = FAISS.from_texts(texts, embeddings)\n",
        "    chain = load_qa_chain(OpenAI(temperature=0), chain_type=\"stuff\")\n",
        "    question = QUESTIONS[q_index][1]\n",
        "    docs = docsearch.similarity_search(question, k=NUM_PIECES_CONTEXT)\n",
        "    answer = chain.run(input_documents=docs, question=question)\n",
        "    df.at[i, QUESTIONS[q_index][0]] = answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EUahO2OL2Ox",
        "outputId": "6a6f0e7e-0261-4dca-833d-d8ba200dd079"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PDF number:: 0it [00:00, ?it/s]\n",
            "Question number:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Question number:  50%|█████     | 1/2 [00:04<00:04,  4.98s/it]\u001b[A\n",
            "Question number: 100%|██████████| 2/2 [00:18<00:00,  9.39s/it]\n",
            "PDF number:: 1it [00:18, 18.80s/it]\n",
            "Question number:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
            "Question number:  50%|█████     | 1/2 [00:13<00:13, 13.66s/it]\u001b[A\n",
            "Question number: 100%|██████████| 2/2 [00:28<00:00, 14.23s/it]\n",
            "PDF number:: 2it [00:47, 23.64s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "keQFuZjVNlxP",
        "outputId": "794a3e5f-85dd-457a-880c-d442f67f1d40"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             filename  \\\n",
              "0  /content/CauseRelatedMarketing.pdf   \n",
              "1            /content/BrandSelfie.pdf   \n",
              "\n",
              "                                                                                                 Topic  \\\n",
              "0              The topic of the article is the effect of cause-related marketing on consumer behavior.   \n",
              "1   The article discusses the effects of self-referencing on persuasion, native advertising in onli...   \n",
              "\n",
              "                                                                                                  Data  \n",
              "0   The data used for the analysis included 159 papers, reporting on 237 studies, from 65 journals,...  \n",
              "1   The data used for the analysis included Twitter image data, the number of likes and comments ea...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a105505-8a9b-40c9-9570-23889898e043\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/CauseRelatedMarketing.pdf</td>\n",
              "      <td>The topic of the article is the effect of cause-related marketing on consumer behavior.</td>\n",
              "      <td>The data used for the analysis included 159 papers, reporting on 237 studies, from 65 journals,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/BrandSelfie.pdf</td>\n",
              "      <td>The article discusses the effects of self-referencing on persuasion, native advertising in onli...</td>\n",
              "      <td>The data used for the analysis included Twitter image data, the number of likes and comments ea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a105505-8a9b-40c9-9570-23889898e043')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4a105505-8a9b-40c9-9570-23889898e043 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4a105505-8a9b-40c9-9570-23889898e043');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('/content/analyse.xlsx')"
      ],
      "metadata": {
        "id": "LSfGmYleN15A"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iS_9uGFGOIL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Add more functionality from Langchain to your process"
      ],
      "metadata": {
        "id": "81oOqsRXQY_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to learn more about the process, check out the documentation of Langchain. Langchain is the library that we use here to input a PDF file into ChatGPT. Cool stuff you can add if you want to are for example: 1. Make ChatGPT return from which piece of text it found the correct answer, 2. Create a parser to get exactly the data you search for back etc.\n",
        "\n",
        "Langchain Documentation: https://python.langchain.com/en/latest/index.html"
      ],
      "metadata": {
        "id": "9NmAyWLuP7vo"
      }
    }
  ]
}